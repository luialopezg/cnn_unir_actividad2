{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX8gZlVyCCbz"
      },
      "source": [
        "# ACTIVIDAD 2: REDES NEURONALES CONVOLUCIONALES\n",
        "\n",
        "---\n",
        "\n",
        "En esta actividad, vamos a trabajar con Convolutional Neural Networks para resolver un problema de clasificación de imágenes. En particular, vamos a clasificar diez clases que incluyen fundamentalmente animales y vehículos.\n",
        "\n",
        "Como las CNN profundas son un tipo de modelo bastante avanzado y computacionalmente costoso, se recomienda hacer la práctica en Google Colaboratory con soporte para GPUs. En [este enlace](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d) se explica cómo activar un entorno con GPUs. *Nota: para leer las imágenes y estandarizarlas al mismo tamaño se usa la librería opencv. Esta ĺibrería está ya instalada en el entorno de Colab, pero si trabajáis de manera local tendréis que instalarla.*\n",
        "\n",
        "<center><img src=\"https://production-media.paperswithcode.com/datasets/4fdf2b82-2bc3-4f97-ba51-400322b228b1.png\" style=\"text-align: center\" height=\"300px\"></center>\n",
        "\n",
        "El dataset a utilizar consiste en 60000 imágenes a color de 10 clases de animales y vehículos. El dataset en cuestión se denomina [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) y es más complejo que el dataset MNIST que hemos utilizado en la actividad 1. Aunque tiene las mismas clases (10), los animales y vehículos pueden aparecer en distintas poses, en distintas posiciones de la imagen o con otros animales/ vehículos en pantalla (si bien el elemento a clasificar siempre aparece en la posición predominante)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI274F8LQC59"
      },
      "source": [
        "## Carga de los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7tKOZ9BFfki"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import keras.datasets.cifar10 as cifar10\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero, definimos los datos de entrenamiento, validación y prueba\n",
        "(X, Y), (x_test, y_test) = cifar10.load_data()\n",
        "(x_train, x_valid) = (X[:40000], X[40000:])\n",
        "(y_train, y_valid) = (Y[:40000], Y[40000:])"
      ],
      "metadata": {
        "id": "iw0apA7ruy1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2635b603-8939-428b-c98f-b3ec7df5c81a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 12s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizamos como de costumbre\n",
        "x_train = x_train / 255.\n",
        "x_valid = x_valid / 255.\n",
        "x_test = x_test / 255."
      ],
      "metadata": {
        "id": "_HIhp512sPUJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMFhe3COFwSD"
      },
      "source": [
        "# Esta variable contiene un mapeo de número de clase a elemento (animal o vehículo).\n",
        "# La incluimos para ayudarte con la identificación de clases. De ti depende\n",
        "# si quieres utilizar esta variable o no\n",
        "MAP_ELEMENTS = {\n",
        "    0: 'avion', 1: 'coche', 2: 'ave',\n",
        "    3: 'gato', 4: 'ciervo', 5: 'perro', 6: 'rana',\n",
        "    7: 'caballo', 8: 'barco', 9: 'camion'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función auxiliar para convertir las etiquetas a codificación one-hot\n",
        "def convert_to_one_hot(labels, num_classes):\n",
        "    return np.squeeze(np.array([to_categorical(label, num_classes=num_classes) for label in labels]))\n",
        "\n",
        "# Convertimos las etiquetas de entrenamiento, validación y prueba\n",
        "num_classes = 10\n",
        "y_train_one_hot = convert_to_one_hot(y_train, num_classes)\n",
        "y_valid_one_hot = convert_to_one_hot(y_valid, num_classes)\n",
        "y_test_one_hot = convert_to_one_hot(y_test, num_classes)\n",
        "\n",
        "# Verificamos las conversiones\n",
        "print(y_train_one_hot.shape)\n",
        "print(y_valid_one_hot.shape)\n",
        "print(y_test_one_hot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOoQ7_0GrylF",
        "outputId": "a068ee11-e29e-46d8-c897-28d96fdc78aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 10)\n",
            "(10000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBbmz9DMhVhc"
      },
      "source": [
        "## Ejercicio\n",
        "\n",
        "Utilizando Convolutional Neural Networks con Keras, entrenar un clasificador que sea capaz de reconocer una imagen de las incluidas en CIFAR-10 con la mayor accuracy posible. Redactar un informe analizando varias de las alternativas probadas y los resultados obtenidos.\n",
        "\n",
        "A continuación se detallan una serie de aspectos orientativos que podrían ser analizados en vuestro informe (no es necesario tratar todos ellos ni mucho menos, esto son ideas orientativas de aspectos que podéis explorar):\n",
        "\n",
        "*   Análisis de los datos a utilizar.\n",
        "*   Análisis de resultados, obtención de métricas de *precision* y *recall* por clase y análisis de qué clases obtienen mejores o peores resultados.\n",
        "*   Análisis visual de los errores de la red. ¿Qué tipo de imágenes dan más problemas a nuestro modelo?\n",
        "*   Comparación de modelos CNNs con un modelo de Fully Connected para este problema.\n",
        "*   Utilización de distintas arquitecturas CNNs, comentando aspectos como su profundidad, hiperparámetros utilizados, optimizador, uso de técnicas de regularización, *batch normalization*, etc.\n",
        "*   [ *algo más difícil* ] Utilización de *data augmentation*. Esto puede conseguirse con la clase [ImageDataGenerator](https://keras.io/preprocessing/image/#imagedatagenerator-class) de Keras.\n",
        "\n",
        "Notas:\n",
        "* Te recomendamos mantener los conjuntos de entrenamiento, test y prueba que se crean en el Notebook. No obstante, si crees que modificando tales conjuntos puedes lograr mejores resultados (o que puedes lograr los mismos resultados con menos datos, lo cual es también un logro), eres libre de hacerlo.\n",
        "* No es necesario mostrar en el notebook las trazas de entrenamiento de todos los modelos entrenados, si bien una buena idea seria guardar gráficas de esos entrenamientos para el análisis. Sin embargo, **se debe mostrar el entrenamiento completo del mejor modelo obtenido y la evaluación de los datos de test con este modelo**."
      ]
    }
  ]
}